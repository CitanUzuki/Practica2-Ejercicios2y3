{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z45XtMKA2edH",
        "outputId": "035ba2ed-95d5-4fdf-9938-577fb0bc7a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeras filas del dataset:\n",
            "     X      Y\n",
            "0  108  392,5\n",
            "1   19   46,2\n",
            "2   13   15,7\n",
            "3  124  422,2\n",
            "4   40  119,4\n",
            "Mean Squared Error (Regresión Lineal): 875.0434234424168\n",
            "Mean Squared Error (K-Vecinos más Cercanos para Regresión): 2718.6243076923074\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 13644.1113 - val_loss: 30446.3984\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 13637.3623 - val_loss: 30431.6211\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 13630.5225 - val_loss: 30417.0742\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 13625.1172 - val_loss: 30402.3789\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 13618.7822 - val_loss: 30387.7461\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 13611.7861 - val_loss: 30373.3672\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 13606.6953 - val_loss: 30358.7695\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 13600.8066 - val_loss: 30344.4414\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 13593.3477 - val_loss: 30330.7578\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 13589.0596 - val_loss: 30316.8320\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Mean Squared Error (Red Neuronal para Regresión): 30316.832284905922\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Cargar el dataset desde el archivo de texto, considerando que las columnas están separadas por tabulaciones\n",
        "data = pd.read_csv('AutoInsurSweden.txt', delimiter='\\t')\n",
        "\n",
        "# Explorar el dataset\n",
        "print(\"Primeras filas del dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Convertir la columna 'Y' a números de punto flotante\n",
        "data['Y'] = data['Y'].str.replace(',', '.').astype(float)\n",
        "\n",
        "# Separar características (X) y etiquetas (Y)\n",
        "X = data[['X']]  # Asumiendo que 'X' es la columna de número de reclamaciones\n",
        "Y = data[['Y']]  # Asumiendo que 'Y' es la columna de pagos totales en miles de coronas suecas\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar características para algunos algoritmos\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Implementar Regresión Lineal\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train_scaled, Y_train)\n",
        "y_pred_linear = linear_model.predict(X_test_scaled)\n",
        "mse_linear = mean_squared_error(Y_test, y_pred_linear)\n",
        "print(f'Mean Squared Error (Regresión Lineal): {mse_linear}')\n",
        "\n",
        "# Implementar K-Vecinos más Cercanos para Regresión\n",
        "knn_model = KNeighborsRegressor()\n",
        "knn_model.fit(X_train_scaled, Y_train)\n",
        "y_pred_knn = knn_model.predict(X_test_scaled)\n",
        "mse_knn = mean_squared_error(Y_test, y_pred_knn)\n",
        "print(f'Mean Squared Error (K-Vecinos más Cercanos para Regresión): {mse_knn}')\n",
        "\n",
        "# Implementar una red neuronal con TensorFlow para Regresión\n",
        "neural_network = Sequential()\n",
        "neural_network.add(Dense(units=64, activation='relu', input_dim=1))  # Ajusta input_dim según el número de características\n",
        "neural_network.add(Dense(units=1, activation='linear'))  # Linear activation para regresión\n",
        "neural_network.compile(optimizer='adam', loss='mean_squared_error')  # Usamos MSE para regresión\n",
        "neural_network.fit(X_train_scaled, Y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, Y_test))\n",
        "y_pred_nn = neural_network.predict(X_test_scaled)\n",
        "mse_nn = mean_squared_error(Y_test, y_pred_nn)\n",
        "print(f'Mean Squared Error (Red Neuronal para Regresión): {mse_nn}')\n",
        "\n"
      ]
    }
  ]
}